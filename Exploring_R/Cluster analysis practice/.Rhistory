n_t <- 40       #number of cycles
n_s <- 3        #number os states - healthy, diseased, dead
n_c <- 1000     #cohort size - number of people in a group being simulated over time
v_state_names <- c("Healthy", "Diseased", "Dead")
trans_mat <- array(NA_real_,
dim = c(n_s, n_s, n_t),               #ist dim is the one coming from (n_s) and 2nd dim is the one we're going to (also n_s), and then we need number of cycles (remember 3D -> x, y and t)
dimnames = list(v_state_names,
v_state_names,
cylce = 1:n_t))
trans_mat
trans_mat[2, 1, 1:n_t] <- 0                     #we know we can't go from state 2 (diseased) to state 1 (healthy) at any time point, so the third entry here for time could be 1:n_t or just left out i.e. [2, 1, ], in any case we equate to 0 for that entry
trans_mat[3, 1, ] <- 0                          #left time entry empty here s explained above
trans_mat[3, 2, ] <- 0
trans_mat[1, 2, ] <- 0.03                  #we know this from the arbirary assignment in 2_2 of this series. Also, we left time entry empty because it applies to all times
trans_mat[3, 3, ] <- 1                    # same as above. Also, dead to dead is for sure duh!
trans_mat[1, 3,  1:10] <- .01          # Prb of dying after being healthy. choosing times 1-10 (imagine that they're age) here and equating to .01 makes sense as if you're young you hve a lower prb
trans_mat[1, 3, 11:20] <- .02
trans_mat[1, 3, 21:30] <- .04
trans_mat[1, 3, 31:40] <- .08
trans_mat[2, 3, ] <- trans_mat[1, 3, ] + .04          #Prb of going from diseased to healthy is same as healthy to dead + 4%
trans_mat  #still have NAs, ***my guess is due to having no assignments for healthy to healthy and diseased to diseased
trans_mat[2, 1, 1:n_t] <- 0                     #we know we can't go from state 2 (diseased) to state 1 (healthy) at any time point, so the third entry here for time could be 1:n_t or just left out i.e. [2, 1, ], in any case we equate to 0 for that entry
trans_mat[3, 1, ] <- 0                          #left time entry empty here s explained above
trans_mat[3, 2, ] <- 0
trans_mat[1, 2, ] <- 0.03                  #we know this from the arbirary assignment in 2_2 of this series. Also, we left time entry empty because it applies to all times
trans_mat[3, 3, ] <- 1                    # same as above. Also, dead to dead is for sure duh!
trans_mat[1, 3,  1:10] <- .01          # Prb of dying after being healthy. choosing times 1-10 (imagine that they're age) here and equating to .01 makes sense as if you're young you hve a lower prb
trans_mat[1, 3, 11:20] <- .02
trans_mat[1, 3, 21:30] <- .04
trans_mat[1, 3, 31:40] <- .08
trans_mat[2, 3, ] <- trans_mat[1, 3, ] + .04          #Prb of going from diseased to healthy is same as healthy to dead + 4%
trans_mat  #still have NAs, ***my guess is due to having no assignments for healthy to healthy and diseased to diseased
trans_mat[2, 2, ] <- 1 - trans_mat[2, 3, ]     #P(remaining diseased) = 1 - P(dying|diseased), I'd imagine same for P(healthy), with adjustments ofcourse! -> I'd be WRONGGGG!!!!!
trans_mat[1, , ]   # when we run this we see the Prob of going to each of the states, Healthy is still NA; but we see that dead increases over time
trans_mat[1, , 40]    #run this, and get 1 line
sum(trans_mat[1, , 40])   #output is NA
sum(trans_mat[1, , 40], na.rm = TRUE)    #works fine. However, we want something more efficient than typing so many lines of code
trans_mat[1, 1, ] <- 1 - apply(trans_mat[1, , ], 2, sum, na.rm = TRUE)  #See ?apply above. We use 2 as Margin to apply to columns -> think about it we are adding diseased values to dead values across columns
trans_mat                      #No NAs
state_membership <- array(NA_real_,
dim = c(n_t, n_s),
dimnames = list(cycle = 1:n_t,
state = v_state_names))     #we fill the arrays with NAs at the start bcos we want the first dimension to be the number of cycles and the second to be the number of states
View(state_membership)
state_membership[1,] <- c(n_c, 0, 0)  # basically row 1, col 1 is set to n_c = 1000
for (i in 2:n_t)
{
state_membership[i,] <- state_membership[i - 1, ] %*% trans_mat[ , , i - 1]
}
state_membership  # We use state membership to iterate to the nth step.
library(tidyverse)
library(naniar)     #visualise missing data
library(gtExtras)   #create beautiful tables
View(airquality)
View(starwars)
heller <- miss_var_summary(airquality)
View(heller)
table_x <- gt(heller)
table_viz <- gt_theme_guardian(table_x)
(table_viz2 <- tab_header(table_viz, title = "Missingness of variables"))
rm(list = ls())
?gt
?tab_header
miss_var_summary(airquality) %>%
gt() %>%                                        # everything from here is just themes
gt_theme_guardian() %>%                         #...
tab_header(title = "Missingness of variables")  #...
gg_miss_var(airquality)
## Table of observations with missing data
airquality %>%
filter(!complete.cases(.)) %>%        # recall ! => NOT complete cases; (.) => ALL of the data
head(10) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Rows that contain missing values")
vis_miss(airquality)    #numerical distribn of where the values are missing in the number spread
### The rel. to one variable:
airquality %>%
mutate(
Missing_Ozone = factor(is.na(Ozone),
levels = c("TRUE", "FALSE"),
labels = c("Missing", "Not Missing")
)
) %>%
ggplot(aes(x= Wind, fill = Missing_Ozone)) +
geom_histogram(position = "stack") +
labs(title = "Distribution of Wind Speeds for Missing vs Non-Missing Ozone Values",
x = "Wind speed",
y="Ozone Observations",
fill = "Missingness") +
theme_bw()
airquality %>%
mutate(
Missing_Ozone = factor(is.na(Ozone),
levels = c("FALSE", "TRUE"),
labels = c("Not Missing", "Missing")
)
) %>%
ggplot(aes(x= Wind, fill = Missing_Ozone)) +
geom_histogram(position = "stack") +
labs(title = "Distribution of Wind Speeds for Missing vs Non-Missing Ozone Values",
x = "Wind speed",
y="Ozone Observations",
fill = "Missingness") +
theme_bw()
airquality %>%
select(Ozone, Solar.R, Wind, Temp) %>%
ggplot(aes(x = Wind,
y = Temp,
size = Solar.R,
colour = is.na(Ozone))) +
geom_point(alpha = 0.7) +
facet_wrap(~is.na(Ozone)) +
labs(title = "Missing Ozone Data by Wind and Temperature",
color = "Missing Ozone data",
y = "Temperature",
x = "Wind speed") +
theme_bw()
miss_var_summary(starwars) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Missingness of variables")
gg_miss_var(starwars)
starwars %>%
filter(!complete.cases(.)) %>%        # is.na() works as well as !complete.cases()
head(10) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Rows that contain missing values")          #doesn't work due to nature of the data - when i try a variable (e.g hair_color) with missing values, it works
starwars %>%
filter(!complete.cases('hair_color')) %>%        # is.na() works as well as !complete.cases()
head(10) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Rows that contain missing values")          #doesn't work due to nature of the data - when i try a variable (e.g hair_color) with missing values, it works
starwars %>%
filter(!complete.cases('hair_color', 'birth_year')) %>%        # is.na() works as well as !complete.cases()
head(10) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Rows that contain missing values")          #doesn't work due to nature of the data - when i try a variable (e.g hair_color) with missing values, it works
#tabulate the missing values:
starwars %>%
select(name, mass, height, hair_color) %>%
head(15) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "starwars characters") %>%
gt_highlight_rows(rows = is.na(mass),
fill = "steelblue") %>%
gt_highlight_rows(rows = is.na(hair_color),
fill = "lightpink") %>%
gt_highlight_rows(rows = is.na(height),
fill = "yellow")
starwars %>%
select(name, mass, height, hair_color) %>%
drop_na(mass) %>%
head(20) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Starwars characters")           #You can see records for "Wilhuff Tarkin" are gone
starwars %>%
select(name, hair_color, species) %>%
head(5) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Starwars character hair color and species") %>%
gt_highlight_rows(rows = is.na(hair_color),
fill = "lightpink")
starwars %>%
select(name, hair_color, species) %>%
filter(species == "Droid") %>%
mutate(hair_color = case_when(
is.na(hair_color) &
species == "Droid" ~ "none",
TRUE ~ hair_color)) %>%
gt() %>%
gt_theme_guardian() %>%
tab_header(title = "Starwars characters")       #"is.na(hair_color) & species == "Droid" ~ "none"" => Basically if haircolor is NA AND species = droid, then (~) change to "none",.....
#First lets view missing height data as a table:
starwars %>%
select(name, height) %>%
filter(is.na(height)) %>%
gt() %>%
gt_theme_espn() %>%
tab_header(title = "Starwars characters")
starwars %>%
mutate(height = case_when(
is.na(height) ~ median(starwars$height,
na.rm = TRUE),                  #when we calc the median, we need to exclude missing values (NA)
TRUE ~ height)) %>%
select(name,height) %>%
arrange(name) %>%
gt() %>%
gt_theme_dark() %>%
tab_header(title = "starwars charcters") %>%
gt_highlight_rows(rows = name %in% c("Arvel Crynyd", "Finn", "Rey",
"Poe Dameron", "BB8",
"Captain Phasma"),
fill = "steelblue")
reticulate::repl_python()
library(readr)
mydata <- read_csv("ClusterData.csv")
setwd("~/UK - UEL_UNICAF/Module 1 - Data Ecology/WK3-practice R/Practicing R/Cluster analysis practice")
library(readr)
mydata <- read_csv("ClusterData.csv")
str(mydata)
pairs(mydata)     #ERROR:Error in pairs.default(mydata) : non-numeric argument to 'pairs' => This is because there is a char array in the data as is, see below:
head(mydata)
pairs(mydata[2:9])   #a pairs plot will provide a scatter plot for all possible combinations
library(psych)
pairs.panels(mydata[,-1],
gap = 0,
bg = c("red", "yellow", "blue")[mydata$Company],
pch = 21)
plot(mydata$Fuel_Cost~ mydata$Sales)
with(mydata, text(mydata$Fuel_Cost ~ mydata$Sales, labels = mydata$Company, pos = 4, cex =0.5))
z <- mydata[, -c(1,1)]
nasss <- mydata[,-1]    #same output a above
means <- apply(z, 2, mean)     #### 2 here means we are applying the fuction "mean" to columns
sds <- apply(z,2,sd)
nor <- scale(z, center = means, scale = sds)
distance = dist(nor)
distance         #output is euclidean distance amongst all records
print(distance,digits = 3)
mydata.hclust = hclust(distance, method = "complete")
plot(mydata.hclust)
plot(mydata.hclust,labels=mydata$Company,main='Default from hclust')
mydata.hclust_avg <- hclust(distance, method = "average")
plot(mydata.hclust_avg, hang = -1)
plot(mydata.hclust_avg,hang=-1, labels=mydata$Company,main='Default from hclust')
member.c = cutree(mydata.hclust,3)
member.a = cutree(mydata.hclust_avg, 3)
table(member.c, member.a)     ###OUTPUT = using avg linkage, there were 18 (13 +5) coys belonging to cluster 1, 1 coy in cluster 2 and so on;
aggregate(nor, list(member.c),mean)     # we can check either mthd. let's use complete for now
#We can also observe the aggregate comparisons in non-normalised units:
aggregate(mydata[,-c(1,1)], list(member.c), mean)
library(cluster)
plot(silhouette(cutree(mydata.hclust,3), distance))   #### Based on the plot, if any bar comes on the negative side then we can conclude that that particular data is an outlier and we can remove it from our analysis
wss <- (nrow(nor)-1) * sum(apply(nor,2,var))
for (i in 2:20) wss[i] <- sum(kmeans(nor,centers = i)$withinss)
plot(1:20,wss,type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
### K Means clustering
set.seed(123)
kc <- kmeans(nor,3)
kc      ###***See meaning of output in youtube vid (2nd link at top) from 15:33 mins
ot<-nor
datadistshortset <- dist(ot, method = "euclidean")
hc1 <- hclust(datadistshortset, method = "complete")
pamvshortset <- pam(datadistshortset, 4, diss = FALSE)
clusplot(pamvshortset, shade = FALSE, labels = 2, col.clus = "blue", col.p ="red", span = FALSE, main = "Cluster Mapping", cex =1.2)
install.packages("factoextra")
library(factoextra)
k2 <- kmeans(nor, centers = 3, nstart = 25)
str(k2)
fviz_cluster(k2, data = nor)
fviz_nbclust(nor, kmeans, method = "wss")     #The results suggest that 4 is the optimal number of clusters as it appears to be the bend in the knee.
fviz_nbclust(nor, kmeans, method = "silhouette")        #This suggests as before that 5 is the optimal number of clusters
fviz_nbclust(nor, kmeans, method = "gap_stat")      # In this method also optimal number of cluster is 5.
